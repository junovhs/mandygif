================================================================================
FILE: .gitignore
================================================================================
# Rust
target/
Cargo.lock
**/*.rs.bk
*.pdb

# OS
.DS_Store
Thumbs.db
desktop.ini

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Build artifacts
*.dmg
*.exe
*.AppImage
*.deb
*.rpm

# Temp/test files
/test_output/
*.mp4
*.gif
*.webp

================================================================================
FILE: Cargo.toml
================================================================================
[workspace]
members = [
    "core/protocol",
    "core/recorder-linux",
    "core/recorder-mac", 
    "core/recorder-win",
    "core/encoder",
    "core/captions",
    "core/region-selector",
    "ui",
]
resolver = "2"

[workspace.package]
version = "0.1.0"
edition = "2021"
authors = ["MandyGIF Contributors"]
license = "MIT OR Apache-2.0"

[workspace.dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
thiserror = "1.0"
tokio = { version = "1.35", features = ["full"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

================================================================================
FILE: README.md
================================================================================

# MandyGIF

**MandyGIF** is a high-performance, native screen recording and GIF creation tool written in Rust. It provides a modern, transparent overlay interface designed for capturing specific regions of the screen with pixel-perfect precision.

Unlike traditional screen recorders that use heavy Electron wrappers or separate selection windows, MandyGIF leverages a transparent Dioxus window that acts as both the viewport and the controller, offering a seamless "what you see is what you get" recording experience.

---

## Technical Architecture

MandyGIF is built as a Rust workspace comprising a unified UI and specialized backend cores.

### 1. Frontend (UI)
*   **Framework:** [Dioxus](https://dioxuslabs.com/) (Desktop).
*   **Rendering:** WebKit/WebView via `wry` and `tao`.
*   **Window Management:** Custom implementation for transparent, undecorated, always-on-top windows with pass-through input handling and native resizing logic.
*   **State Management:** Dioxus Signals and Context API.

### 2. Recording Core (`mandygif-recorder-linux`)
*   **Engine:** GStreamer.
*   **Integration:** Directly linked as a Rust library (no IPC latency).
*   **Pipeline:**
    *   **Source:** `ximagesrc` (X11 capture) with zero-copy pointers where supported.
    *   **Encoding:** Hardware-accelerated H.264 (via `x264enc`) wrapped in MP4 containers.
    *   **Synchronization:** Real-time PTS (Presentation Time Stamp) tracking for accurate duration UI updates.

### 3. Encoding Core (`mandygif-encoder`)
*   **Engine:** FFmpeg (spawned subprocess).
*   **Isolation:** Runs independently to prevent UI freezing during heavy rendering tasks.
*   **Capabilities:**
    *   **GIF:** 2-pass encoding with `palettegen` and `paletteuse` for high-quality dithering.
    *   **MP4:** Re-encoding with CRF (Constant Rate Factor) for optimization.
    *   **WebP:** Support for both lossy and lossless compression.
*   **Protocol:** Communicates via a strongly-typed JSONL protocol over `stdin`/`stdout`.

---

## Prerequisites (Linux)

MandyGIF currently targets Linux (X11). Ensure the following dependencies are installed:

### System Libraries
```bash
# Debian/Ubuntu
sudo apt-get update
sudo apt-get install -y \
    build-essential \
    libssl-dev \
    libgtk-3-dev \
    libwebkit2gtk-4.0-dev \
    libxdo-dev \
    libgstreamer1.0-dev \
    libgstreamer-plugins-base1.0-dev \
    gstreamer1.0-plugins-base \
    gstreamer1.0-plugins-good \
    gstreamer1.0-plugins-bad \
    gstreamer1.0-plugins-ugly \
    ffmpeg
```

*Note: `gstreamer1.0-plugins-ugly` is required for the `x264` encoder.*

---

## Build & Run

The project is managed via Cargo.

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/junovhs/mandygif.git
    cd mandygif
    ```

2.  **Build the project:**
    ```bash
    cargo build --release
    ```

3.  **Run the application:**
    ```bash
    cargo run --bin mandygif
    ```

---

## Usage

1.  **Position:** Launch the app. Drag the window via the "MandyGIF" header or resize the edges to frame the content you wish to record.
2.  **Record:** Click the **RECORD** button. The border will turn red.
3.  **Stop:** Click **STOP** to finish capturing. The raw footage is saved temporarily to `/tmp/`.
4.  **Export:**
    *   Select your desired output format (GIF, MP4, or WebP).
    *   Click **EXPORT**.
    *   The final file will be generated in `/tmp/export.[ext]`.

---

## Project Status

| Component | Status | Notes |
| :--- | :--- | :--- |
| **UI** | âœ… Beta | Resizing, dragging, and state management fully functional. |
| **Linux Recorder** | âœ… Beta | X11 support verified. Wayland support pending. |
| **Encoder** | âœ… Stable | Supports High-Quality GIF, MP4, WebP. |
| **Windows Recorder** | ðŸš§ Planned | WGC (Windows Graphics Capture) implementation pending. |
| **macOS Recorder** | ðŸš§ Planned | ScreenCaptureKit implementation pending. |

## License

MIT / Apache-2.0


================================================================================
FILE: core/captions/Cargo.toml
================================================================================
[package]
name = "mandygif-captions"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[dependencies]
mandygif-protocol = { path = "../protocol" }
anyhow.workspace = true

# Phase 1: Will use ffmpeg drawtext (external process)
# Phase 2: skia-safe for direct rendering
# skia-safe = { version = "0.74", optional = true }

[features]
default = []
skia = []  # Enable for Phase 2

================================================================================
FILE: core/captions/src/lib.rs
================================================================================
//! Caption rendering module
//!
//! Phase 1: Generates ffmpeg drawtext filter strings.

#![allow(clippy::cast_possible_truncation)]
#![allow(clippy::cast_sign_loss)]
#![allow(clippy::cast_precision_loss)]
#![allow(clippy::many_single_char_names)]

use anyhow::Result;
use mandygif_protocol::Caption;

/// Generate ffmpeg drawtext filter for a caption (Phase 1)
///
/// # Errors
/// Returns error if color parsing fails.
pub fn ffmpeg_text(caption: &Caption, w: u32, h: u32) -> Result<String> {
    let x = (caption.rect.x * w as f32) as u32;
    let y = (caption.rect.y * h as f32) as u32;

    // Validate colors before generating string
    let font_color = ff_color(&caption.style.color, 1.0)?;
    let border_color = ff_color(&caption.style.stroke, 1.0)?;

    Ok(format!(
        "drawtext=text='{}':fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:fontsize={}:fontcolor={}:borderw=2:bordercolor={}:x={}:y={}:enable='between(t,{},{})'",
        caption.text.replace('\'', "\\'"),
        caption.style.size,
        font_color,
        border_color,
        x,
        y,
        caption.start_ms as f64 / 1000.0,
        caption.end_ms as f64 / 1000.0
    ))
}

/// Combine multiple captions into a filter chain
///
/// # Errors
/// Returns error if any caption fails to generate (e.g. bad color).
pub fn chain_filters(captions: &[Caption], w: u32, h: u32) -> Result<String> {
    let mut filters = Vec::new();
    for c in captions {
        filters.push(ffmpeg_text(c, w, h)?);
    }
    Ok(filters.join(","))
}

/// Generate ffmpeg drawtext filter using expressions (`main_w/main_h`)
/// Works correctly after scaling operations.
///
/// # Errors
/// Returns error if color parsing fails.
pub fn ffmpeg_text_expr(caption: &Caption) -> Result<String> {
    let x_expr = format!("(main_w*{:.6})", caption.rect.x);
    let y_expr = format!("(main_h*{:.6})", caption.rect.y);
    let start_s = (caption.start_ms as f64) / 1000.0;
    let end_s = (caption.end_ms as f64) / 1000.0;

    let fontcolor = ff_color(&caption.style.color, 1.0)?;
    let bordercolor = ff_color(&caption.style.stroke, 1.0)?;

    Ok(format!(
        "drawtext=text='{}':fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:fontsize={}:fontcolor={}:borderw=2:bordercolor={}:x={}:y={}:enable='between(t,{:.3},{:.3})'",
        caption.text.replace('\'', "\\'"),
        caption.style.size,
        fontcolor,
        bordercolor,
        x_expr,
        y_expr,
        start_s,
        end_s
    ))
}

/// Combine multiple captions using expression-based positioning.
///
/// # Errors
/// Returns error if any caption fails to generate.
pub fn chain_filters_expr(captions: &[Caption]) -> Result<String> {
    let mut filters = Vec::new();
    for c in captions {
        filters.push(ffmpeg_text_expr(c)?);
    }
    Ok(filters.join(","))
}

/// Normalize CSS-like hex colors to ffmpeg syntax.
/// #RGB/#RRGGBB/#RGBA/#RRGGBBAA -> 0xRRGGBB or 0xRRGGBB@A.A
#[allow(clippy::cast_lossless)]
fn ff_color(input: &str, default_alpha: f32) -> Result<String> {
    let s = input.trim();
    if s.starts_with("0x") || s.contains('@') {
        return Ok(s.to_string());
    }

    let hex = s.strip_prefix('#').unwrap_or(s);
    let (r, g, b, a) = match hex.len() {
        3 => {
            let r = u8::from_str_radix(&hex[0..1].repeat(2), 16)?;
            let g = u8::from_str_radix(&hex[1..2].repeat(2), 16)?;
            let b = u8::from_str_radix(&hex[2..3].repeat(2), 16)?;
            (r, g, b, (default_alpha * 255.0).round() as u8)
        }
        4 => {
            let r = u8::from_str_radix(&hex[0..1].repeat(2), 16)?;
            let g = u8::from_str_radix(&hex[1..2].repeat(2), 16)?;
            let b = u8::from_str_radix(&hex[2..3].repeat(2), 16)?;
            let a = u8::from_str_radix(&hex[3..4].repeat(2), 16)?;
            (r, g, b, (f32::from(a) / 15.0 * 255.0).round() as u8)
        }
        6 => {
            let r = u8::from_str_radix(&hex[0..2], 16)?;
            let g = u8::from_str_radix(&hex[2..4], 16)?;
            let b = u8::from_str_radix(&hex[4..6], 16)?;
            (r, g, b, (default_alpha * 255.0).round() as u8)
        }
        8 => {
            let r = u8::from_str_radix(&hex[0..2], 16)?;
            let g = u8::from_str_radix(&hex[2..4], 16)?;
            let b = u8::from_str_radix(&hex[4..6], 16)?;
            let a = u8::from_str_radix(&hex[6..8], 16)?;
            (r, g, b, a)
        }
        _ => return Err(anyhow::anyhow!("Invalid hex color format: {s}")),
    };

    if a == 255 {
        Ok(format!("0x{r:02X}{g:02X}{b:02X}"))
    } else {
        let alpha = f32::from(a) / 255.0;
        Ok(format!("0x{r:02X}{g:02X}{b:02X}@{alpha:.3}"))
    }
}


================================================================================
FILE: core/encoder/Cargo.toml
================================================================================
[package]
name = "mandygif-encoder"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[[bin]]
name = "encoder"
path = "src/main.rs"

[dependencies]
mandygif-protocol = { path = "../protocol" }
mandygif-captions = { path = "../captions" }
anyhow.workspace = true
tokio.workspace = true
tracing.workspace = true
tracing-subscriber.workspace = true
serde_json.workspace = true

# GIF encoding
gifski = "1.14"
imgref = "1.10"
rgb = "0.8"

# Image loading
image = "0.25"

# Temp directories
tempfile = "3.10"

================================================================================
FILE: core/encoder/src/ffmpeg.rs
================================================================================
#![allow(clippy::cast_precision_loss)]
#![allow(clippy::uninlined_format_args)]

use anyhow::{bail, Context, Result};
use mandygif_captions::chain_filters_expr;
use mandygif_protocol::Caption;
use std::process::Command;
use tracing::info;

/// Check if ffmpeg is available.
pub fn check_ffmpeg() -> Result<()> {
    let output = Command::new("ffmpeg")
        .arg("-version")
        .output()
        .context("ffmpeg not found - please install ffmpeg")?;

    if !output.status.success() {
        bail!("ffmpeg exists but returned error");
    }

    let version = String::from_utf8_lossy(&output.stdout);
    let first_line = version.lines().next().unwrap_or("unknown");
    info!("Using {}", first_line);
    Ok(())
}

/// Build ffmpeg video filter string (fps, scale, captions).
///
/// # Errors
/// Returns error if caption filter generation fails.
pub fn build_filter(fps: u32, scale: Option<u32>, caps: &[Caption]) -> Result<String> {
    let mut filters = vec![format!("fps={}", fps)];

    // FIX: Use -2 instead of -1 to ensure height is divisible by 2 (required for MP4/H.264)
    if let Some(width) = scale {
        filters.push(format!("scale={width}:-2:flags=lanczos"));
    } else {
        // If no scaling is requested, ensure input dimensions are even
        filters.push("scale=trunc(iw/2)*2:trunc(ih/2)*2".to_string());
    }

    // Add caption filters after scaling
    if !caps.is_empty() {
        filters.push(chain_filters_expr(caps)?);
    }

    Ok(filters.join(","))
}

/// Convert milliseconds to seconds string.
#[must_use]
pub fn ms_to_sec(ms: u64) -> String {
    format!("{:.3}", (ms as f64) / 1000.0)
}


================================================================================
FILE: core/encoder/src/gif.rs
================================================================================
#![allow(clippy::uninlined_format_args)]

use crate::ffmpeg::{build_filter, ms_to_sec};
use anyhow::{bail, Context, Result};
use mandygif_protocol::{Caption, LoopMode, TrimRange};
use std::path::Path;
use std::process::{Command, Stdio};
use tracing::{debug, error, warn};

/// Encode GIF using ffmpeg palettegen.
pub fn encode_gif(
    input: &Path,
    trim: &TrimRange,
    fps: u32,
    scale: Option<u32>,
    loop_mode: &LoopMode,
    caps: &[Caption],
    out: &Path,
) -> Result<()> {
    let temp = tempfile::tempdir().context("Failed to create temp dir")?;
    let palette = temp.path().join("palette.png");

    let filter = build_filter(fps, scale, caps)?;
    let start = ms_to_sec(trim.start_ms);
    let dur = ms_to_sec(trim.end_ms.saturating_sub(trim.start_ms));

    // Step 1: Generate palette
    debug!("Generating palette for GIF");
    let output = Command::new("ffmpeg")
        .args(["-ss", &start, "-t", &dur])
        .arg("-i")
        .arg(input)
        .arg("-vf")
        .arg(format!("{filter},palettegen"))
        .arg("-y")
        .arg(&palette)
        .stdout(Stdio::null())
        .stderr(Stdio::piped())
        .output()
        .context("Palette generation failed")?;

    if !output.status.success() {
        let err_msg = String::from_utf8_lossy(&output.stderr);
        error!("Palette gen failed: {}", err_msg);
        bail!("ffmpeg palette generation failed");
    }

    // Step 2: Generate GIF
    debug!("Encoding GIF with palette");
    let mut cmd = Command::new("ffmpeg");
    cmd.args(["-ss", &start, "-t", &dur])
        .arg("-i")
        .arg(input)
        .arg("-i")
        .arg(&palette)
        .arg("-lavfi")
        .arg(format!("{filter} [x]; [x][1:v] paletteuse"));

    match loop_mode {
        LoopMode::Once => {
            cmd.arg("-loop").arg("-1");
        }
        _ => {
            cmd.arg("-loop").arg("0");
        }
    }

    if matches!(loop_mode, LoopMode::Pingpong) {
        warn!("Ping-pong loop mode not yet implemented for GIF");
    }

    let output = cmd
        .arg("-y")
        .arg(out)
        .stdout(Stdio::null())
        .stderr(Stdio::piped())
        .output()
        .context("GIF encoding failed")?;

    if !output.status.success() {
        let err_msg = String::from_utf8_lossy(&output.stderr);
        error!("GIF encoding failed: {}", err_msg);
        bail!("ffmpeg GIF encoding failed: {}", err_msg);
    }

    Ok(())
}


================================================================================
FILE: core/encoder/src/main.rs
================================================================================
//! Cross-platform encoder: GIF, MP4, WebP

#![allow(clippy::wildcard_imports)]

mod ffmpeg;
mod gif;
mod video;

use anyhow::{Context, Result};
use mandygif_protocol::*;
use std::io::{self, BufRead, Write};
use tracing::{error, info};

fn main() -> Result<()> {
    // FIX: Force logs to stderr
    tracing_subscriber::fmt()
        .with_writer(std::io::stderr)
        .with_env_filter("info")
        .init();

    info!("encoder starting (protocol v{})", PROTOCOL_VERSION);
    ffmpeg::check_ffmpeg()?;

    let stdin = io::stdin();
    let mut stdout = io::stdout();

    for line in stdin.lock().lines() {
        let line = line?;
        if let Err(e) = handle_command(&line, &mut stdout) {
            error!("Command failed: {:#}", e);
            send_error(&mut stdout, ErrorKind::EncodingFailed, e.to_string())?;
        }
    }

    Ok(())
}

fn handle_command(line: &str, out: &mut io::Stdout) -> Result<()> {
    match parse_encoder_command(line)? {
        EncoderCommand::Gif {
            input,
            trim,
            fps,
            scale_px,
            loop_mode,
            captions,
            out: path,
        } => {
            gif::encode_gif(&input, &trim, fps, scale_px, &loop_mode, &captions, &path)?;
            send_done(out, path)?;
        }
        EncoderCommand::Mp4 {
            input,
            trim,
            fps,
            scale_px,
            quality,
            captions,
            out: path,
        } => {
            video::encode_mp4(&input, &trim, fps, scale_px, quality, &captions, &path)?;
            send_done(out, path)?;
        }
        EncoderCommand::Webp {
            input,
            trim,
            fps,
            scale_px,
            quality,
            lossless,
            captions,
            out: path,
        } => {
            video::encode_webp(
                &input, &trim, fps, scale_px, quality, lossless, &captions, &path,
            )?;
            send_done(out, path)?;
        }
    }
    Ok(())
}

fn send_done(stdout: &mut io::Stdout, path: std::path::PathBuf) -> Result<()> {
    let event = EncoderEvent::Done { path };
    let json = to_jsonl(&event)?;
    stdout.write_all(json.as_bytes())?;
    stdout.flush()?;
    Ok(())
}

fn send_error(stdout: &mut io::Stdout, kind: ErrorKind, hint: String) -> Result<()> {
    let event = EncoderEvent::Error { kind, hint };
    let json = to_jsonl(&event)?;
    stdout.write_all(json.as_bytes())?;
    stdout.flush().context("Failed to flush stdout")?;
    Ok(())
}


================================================================================
FILE: core/encoder/src/video.rs
================================================================================
#![allow(clippy::cast_possible_truncation)]
#![allow(clippy::cast_sign_loss)]

use crate::ffmpeg::{build_filter, ms_to_sec};
use anyhow::{bail, Context, Result};
use mandygif_protocol::{Caption, TrimRange};
use std::path::Path;
use std::process::{Command, Stdio};
use tracing::{debug, error};

/// Encode MP4 using ffmpeg.
pub fn encode_mp4(
    input: &Path,
    trim: &TrimRange,
    fps: u32,
    scale: Option<u32>,
    qual: f32,
    caps: &[Caption],
    out: &Path,
) -> Result<()> {
    let crf = (51.0 - (qual * 33.0)).round() as u32;
    let start = ms_to_sec(trim.start_ms);
    let dur = ms_to_sec(trim.end_ms.saturating_sub(trim.start_ms));
    let filter = build_filter(fps, scale, caps)?;

    debug!("Encoding MP4 (CRF {crf})");

    // FIX: Use output() to capture stderr for debugging
    let output = Command::new("ffmpeg")
        .args(["-ss", &start, "-t", &dur])
        .arg("-i")
        .arg(input)
        .arg("-vf")
        .arg(filter)
        .args(["-c:v", "libx264", "-preset", "medium"])
        .arg("-crf")
        .arg(crf.to_string())
        .args(["-pix_fmt", "yuv420p", "-movflags", "+faststart"])
        .arg("-y")
        .arg(out)
        .stdout(Stdio::null())
        .stderr(Stdio::piped())
        .output()
        .context("Failed to execute ffmpeg")?;

    if !output.status.success() {
        let err_msg = String::from_utf8_lossy(&output.stderr);
        error!("FFmpeg stderr: {err_msg}");
        bail!("ffmpeg MP4 encoding failed: {err_msg}");
    }

    Ok(())
}

/// Encode WebP using ffmpeg.
#[allow(clippy::too_many_arguments)]
pub fn encode_webp(
    input: &Path,
    trim: &TrimRange,
    fps: u32,
    scale: Option<u32>,
    qual: f32,
    lossless: bool,
    caps: &[Caption],
    out: &Path,
) -> Result<()> {
    let start = ms_to_sec(trim.start_ms);
    let dur = ms_to_sec(trim.end_ms.saturating_sub(trim.start_ms));
    let filter = build_filter(fps, scale, caps)?;

    let mut cmd = Command::new("ffmpeg");
    cmd.args(["-ss", &start, "-t", &dur])
        .arg("-i")
        .arg(input)
        .arg("-vf")
        .arg(filter);

    if lossless {
        cmd.args(["-lossless", "1"]);
    } else {
        cmd.arg("-quality").arg((qual * 100.0).round().to_string());
    }

    debug!("Encoding WebP");

    // FIX: Use output() to capture stderr
    let output = cmd
        .args(["-loop", "0", "-y"])
        .arg(out)
        .stdout(Stdio::null())
        .stderr(Stdio::piped())
        .output()
        .context("Failed to execute ffmpeg")?;

    if !output.status.success() {
        let err_msg = String::from_utf8_lossy(&output.stderr);
        error!("FFmpeg stderr: {err_msg}");
        bail!("ffmpeg WebP encoding failed: {err_msg}");
    }

    Ok(())
}


================================================================================
FILE: core/protocol/Cargo.toml
================================================================================
[package]
name = "mandygif-protocol"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[dependencies]
serde.workspace = true
serde_json.workspace = true
thiserror.workspace = true
chrono = { version = "0.4", features = ["serde"] }

[dev-dependencies]
serde_json.workspace = true

================================================================================
FILE: core/protocol/src/lib.rs
================================================================================
//! JSONL protocol for IPC between UI, recorder, and encoder processes.
//!
//! Version: 1
//! All messages are newline-delimited JSON for easy parsing and logging.

mod parsing;
mod types;

pub use parsing::*;
pub use types::*;

/// Protocol version - increment when breaking changes occur
pub const PROTOCOL_VERSION: u32 = 1;

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;

    #[test]
    fn test_start_roundtrip() -> Result<(), Box<dyn std::error::Error>> {
        let cmd = RecorderCommand::Start {
            region: CaptureRegion {
                x: 128,
                y: 96,
                width: 640,
                height: 360,
            },
            fps: 30,
            cursor: true,
            out: PathBuf::from("/tmp/clip.mp4"),
        };

        let jsonl = to_jsonl(&cmd)?;
        let parsed = parse_recorder_command(&jsonl)?;
        assert_eq!(cmd, parsed);
        Ok(())
    }

    #[test]
    fn test_gif_roundtrip() -> Result<(), Box<dyn std::error::Error>> {
        let cmd = EncoderCommand::Gif {
            input: PathBuf::from("/tmp/clip.mp4"),
            trim: TrimRange {
                start_ms: 200,
                end_ms: 5200,
            },
            fps: 15,
            scale_px: Some(480),
            loop_mode: LoopMode::Pingpong,
            captions: vec![],
            out: PathBuf::from("/tmp/out.gif"),
        };

        let jsonl = to_jsonl(&cmd)?;
        let parsed = parse_encoder_command(&jsonl)?;
        assert_eq!(cmd, parsed);
        Ok(())
    }
}


================================================================================
FILE: core/protocol/src/parsing.rs
================================================================================
use crate::types::{EncoderCommand, EncoderEvent, RecorderCommand, RecorderEvent};
use serde::Serialize;
use serde_json::Error;

/// Parse a JSONL message into a `RecorderCommand`.
///
/// # Errors
/// Returns `serde_json::Error` if the string is not valid JSON or doesn't match the schema.
pub fn parse_recorder_command(line: &str) -> Result<RecorderCommand, Error> {
    serde_json::from_str(line)
}

/// Parse a JSONL message into a `RecorderEvent`.
///
/// # Errors
/// Returns `serde_json::Error` if the string is not valid JSON or doesn't match the schema.
pub fn parse_recorder_event(line: &str) -> Result<RecorderEvent, Error> {
    serde_json::from_str(line)
}

/// Parse a JSONL message into a `EncoderCommand`.
///
/// # Errors
/// Returns `serde_json::Error` if the string is not valid JSON or doesn't match the schema.
pub fn parse_encoder_command(line: &str) -> Result<EncoderCommand, Error> {
    serde_json::from_str(line)
}

/// Parse a JSONL message into a `EncoderEvent`.
///
/// # Errors
/// Returns `serde_json::Error` if the string is not valid JSON or doesn't match the schema.
pub fn parse_encoder_event(line: &str) -> Result<EncoderEvent, Error> {
    serde_json::from_str(line)
}

/// Serialize a command or event to a JSONL string (with newline).
///
/// # Errors
/// Returns `serde_json::Error` if serialization fails.
pub fn to_jsonl<T: Serialize>(msg: &T) -> Result<String, Error> {
    let mut json = serde_json::to_string(msg)?;
    json.push('\n');
    Ok(json)
}


================================================================================
FILE: core/protocol/src/types.rs
================================================================================
use serde::{Deserialize, Serialize};
use std::path::PathBuf;

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(tag = "cmd", rename_all = "lowercase")]
pub enum RecorderCommand {
    Start {
        region: CaptureRegion,
        fps: u32,
        #[serde(default)]
        cursor: bool,
        out: PathBuf,
    },
    Stop,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(tag = "event", rename_all = "lowercase")]
pub enum RecorderEvent {
    Started { pts_ms: u64 },
    Progress { pts_ms: u64 },
    Stopped { duration_ms: u64, path: PathBuf },
    Error { kind: ErrorKind, hint: String },
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct CaptureRegion {
    pub x: i32,
    pub y: i32,
    pub width: u32,
    pub height: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(tag = "cmd", rename_all = "lowercase")]
pub enum EncoderCommand {
    Gif {
        #[serde(rename = "in")]
        input: PathBuf,
        trim: TrimRange,
        fps: u32,
        scale_px: Option<u32>,
        #[serde(rename = "loop")]
        loop_mode: LoopMode,
        captions: Vec<Caption>,
        out: PathBuf,
    },
    Mp4 {
        #[serde(rename = "in")]
        input: PathBuf,
        trim: TrimRange,
        fps: u32,
        scale_px: Option<u32>,
        quality: f32,
        captions: Vec<Caption>,
        out: PathBuf,
    },
    Webp {
        #[serde(rename = "in")]
        input: PathBuf,
        trim: TrimRange,
        fps: u32,
        scale_px: Option<u32>,
        quality: f32,
        lossless: bool,
        captions: Vec<Caption>,
        out: PathBuf,
    },
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(tag = "event", rename_all = "lowercase")]
pub enum EncoderEvent {
    Progress { percent: u32 },
    Done { path: PathBuf },
    Error { kind: ErrorKind, hint: String },
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct TrimRange {
    pub start_ms: u64,
    pub end_ms: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum LoopMode {
    Normal,
    Pingpong,
    Once,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct Caption {
    pub text: String,
    pub font: String,
    pub style: CaptionStyle,
    pub rect: CaptionRect,
    pub start_ms: u64,
    pub end_ms: u64,
    #[serde(default)]
    pub animation: CaptionAnimation,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct CaptionStyle {
    pub color: String,
    pub stroke: String,
    pub size: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct CaptionRect {
    pub x: f32,
    pub y: f32,
    pub w: f32,
    pub h: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]
#[serde(rename_all = "lowercase")]
pub enum CaptionAnimation {
    #[default]
    None,
    Fade,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ErrorKind {
    PermissionDenied,
    InvalidInput,
    EncodingFailed,
    IoError,
    UnsupportedPlatform,
}


================================================================================
FILE: core/recorder-linux/Cargo.toml
================================================================================
[package]
name = "mandygif-recorder-linux"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[dependencies]
mandygif-protocol = { path = "../protocol" }
anyhow.workspace = true
gstreamer = "0.22"
gstreamer-app = "0.22"
gstreamer-video = "0.22"
tracing.workspace = true


================================================================================
FILE: core/recorder-linux/src/lib.rs
================================================================================
#![allow(clippy::cast_possible_wrap)]

use anyhow::{Context, Result};
use gstreamer as gst;
use gstreamer::prelude::*;
use mandygif_protocol::CaptureRegion;
use std::path::Path;
use std::time::Instant;
use tracing::{error, info};

pub struct Recorder {
    pipeline: gst::Pipeline,
    start_time: Instant,
}

impl Recorder {
    /// Initialize `GStreamer`.
    ///
    /// # Errors
    /// Returns error if `GStreamer` cannot be initialized.
    pub fn init() -> Result<()> {
        gst::init().context("Failed to initialize GStreamer")
    }

    /// Start recording a region to a file.
    ///
    /// # Errors
    /// Returns error if dimensions are invalid or pipeline cannot be constructed/started.
    pub fn start(region: &CaptureRegion, fps: u32, cursor: bool, out: &Path) -> Result<Self> {
        if region.width == 0 || region.height == 0 {
            return Err(anyhow::anyhow!("Invalid dimensions"));
        }

        // Note: qtmux needs to be sent EOS to write the moov atom (file footer)
        let desc = format!(
            "ximagesrc startx={} starty={} endx={} endy={} use-damage=false show-pointer={} ! \
             video/x-raw,framerate={}/1 ! \
             videoconvert ! \
             video/x-raw,format=I420 ! \
             x264enc speed-preset=ultrafast tune=zerolatency ! \
             h264parse ! \
             qtmux name=mux ! \
             filesink location={} sync=false",
            region.x,
            region.y,
            region.x + region.width as i32 - 1,
            region.y + region.height as i32 - 1,
            cursor,
            fps,
            out.display()
        );

        info!("Pipeline: {}", desc);

        let pipeline = gst::parse::launch(&desc)?
            .dynamic_cast::<gst::Pipeline>()
            .map_err(|_| anyhow::anyhow!("Not a pipeline"))?;

        pipeline.set_state(gst::State::Playing)?;

        Ok(Self {
            pipeline,
            start_time: Instant::now(),
        })
    }

    #[must_use]
    pub fn duration_ms(&self) -> u64 {
        u64::try_from(self.start_time.elapsed().as_millis()).unwrap_or(0)
    }

    /// Stop recording and finalize file.
    ///
    /// # Errors
    /// Returns error if pipeline state change fails.
    pub fn stop(self) -> Result<u64> {
        info!("Sending EOS to pipeline...");
        let duration = self.duration_ms();

        // 1. Send EOS event to the pipeline. This tells qtmux to finish the file.
        let eos_sent = self.pipeline.send_event(gst::event::Eos::new());
        if !eos_sent {
            error!("Failed to send EOS event");
        }

        // 2. Wait for the EOS message on the bus.
        // This is CRITICAL. If we stop before this, the MP4 is corrupt (no moov atom).
        if let Some(bus) = self.pipeline.bus() {
            info!("Waiting for EOS...");
            let msg = bus.timed_pop_filtered(
                gst::ClockTime::from_seconds(5), // Wait up to 5s
                &[gst::MessageType::Eos, gst::MessageType::Error],
            );

            if let Some(msg) = msg {
                match msg.view() {
                    gst::MessageView::Eos(_) => info!("EOS received, file finalized."),
                    gst::MessageView::Error(err) => {
                        error!("Pipeline error during stop: {}", err.error());
                    }
                    _ => (),
                }
            } else {
                error!("Timed out waiting for EOS - file might be corrupt");
            }
        }

        // 3. Now it is safe to set NULL
        self.pipeline.set_state(gst::State::Null)?;

        Ok(duration)
    }
}


================================================================================
FILE: core/recorder-mac/Cargo.toml
================================================================================
[package]
name = "mandygif-recorder-mac"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[[bin]]
name = "recorder-mac"
path = "src/main.rs"

[dependencies]
mandygif-protocol = { path = "../protocol" }
anyhow.workspace = true
tokio.workspace = true
tracing.workspace = true
tracing-subscriber.workspace = true
serde_json.workspace = true

[target.'cfg(target_os = "macos")'.dependencies]
# macOS-specific dependencies will go here:
# screencapturekit (when bindings exist)
# cocoa, core-foundation, etc.

================================================================================
FILE: core/recorder-mac/src/main.rs
================================================================================
//! macOS screen recorder using `ScreenCaptureKit` + `VideoToolbox`
//!
//! TODO: Implement `SCStream` capture with `VTCompressionSession` encoding

#![allow(clippy::wildcard_imports)]
#![allow(clippy::doc_markdown)]

use anyhow::Result;
#[cfg(target_os = "macos")]
use mandygif_protocol::*;
#[cfg(target_os = "macos")]
use std::io::{self, BufRead, Write};
#[cfg(target_os = "macos")]
use tracing::info;

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
        .init();

    #[cfg(not(target_os = "macos"))]
    {
        eprintln!("recorder-mac only runs on macOS");
        std::process::exit(1);
    }

    #[cfg(target_os = "macos")]
    {
        info!(
            "recorder-mac starting (STUB), protocol v{}",
            PROTOCOL_VERSION
        );

        let stdin = io::stdin();
        let mut stdout = io::stdout();

        for line in stdin.lock().lines() {
            let line = line?;

            if let Ok(RecorderCommand::Start { .. }) = parse_recorder_command(&line) {
                let err_event = RecorderEvent::Error {
                    kind: ErrorKind::UnsupportedPlatform,
                    hint: "macOS recorder not yet implemented".into(),
                };
                let json = to_jsonl(&err_event)?;
                stdout.write_all(json.as_bytes())?;
                stdout.flush()?;
                break;
            }
        }
        Ok(())
    }
}


================================================================================
FILE: core/recorder-win/Cargo.toml
================================================================================
[package]
name = "mandygif-recorder-win"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[[bin]]
name = "recorder-win"
path = "src/main.rs"

[dependencies]
mandygif-protocol = { path = "../protocol" }
anyhow.workspace = true
tokio.workspace = true
tracing.workspace = true
tracing-subscriber.workspace = true
serde_json.workspace = true

[target.'cfg(target_os = "windows")'.dependencies]
# Windows-specific dependencies will go here:
# windows crate for WGC/DXGI APIs

================================================================================
FILE: core/recorder-win/src/main.rs
================================================================================
//! Windows screen recorder using `Windows.Graphics.Capture` + Media Foundation
//!
//! TODO: Implement WGC + MF H.264 encoding

#![allow(clippy::wildcard_imports)]

use anyhow::Result;
#[cfg(target_os = "windows")]
use mandygif_protocol::*;
#[cfg(target_os = "windows")]
use std::io::{self, BufRead, Write};
#[cfg(target_os = "windows")]
use tracing::info;

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
        .init();

    #[cfg(not(target_os = "windows"))]
    {
        eprintln!("recorder-win only runs on Windows");
        std::process::exit(1);
    }

    #[cfg(target_os = "windows")]
    {
        info!(
            "recorder-win starting (STUB), protocol v{}",
            PROTOCOL_VERSION
        );

        let stdin = io::stdin();
        let mut stdout = io::stdout();

        for line in stdin.lock().lines() {
            let line = line?;

            if let Ok(RecorderCommand::Start { .. }) = parse_recorder_command(&line) {
                let err_event = RecorderEvent::Error {
                    kind: ErrorKind::UnsupportedPlatform,
                    hint: "Windows recorder not yet implemented".into(),
                };
                let json = to_jsonl(&err_event)?;
                stdout.write_all(json.as_bytes())?;
                stdout.flush()?;
                break;
            }
        }
        Ok(())
    }
}


================================================================================
FILE: core/region-selector/Cargo.toml
================================================================================
[package]
name = "mandygif-region-selector"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[[bin]]
name = "region-selector"
path = "src/main.rs"

[dependencies]
anyhow.workspace = true
serde.workspace = true
serde_json.workspace = true
dioxus = { version = "0.6", features = ["desktop"] }
dioxus-logger = "0.6"


================================================================================
FILE: core/region-selector/src/app.rs
================================================================================
use dioxus::desktop::use_window;
use dioxus::prelude::*;
use serde::Serialize;

#[derive(Serialize)]
struct Region {
    x: i32,
    y: i32,
    width: u32,
    height: u32,
}

pub fn App() -> Element {
    let window = use_window();
    let region = use_signal(|| Region {
        x: 100,
        y: 100,
        width: 800,
        height: 600,
    });

    // FIX: Clone window for confirm callback
    let window_confirm = window.clone();
    let confirm = move |_| {
        let r = region.read();
        if let Ok(json) = serde_json::to_string(&*r) {
            println!("{json}");
        }
        window_confirm.close();
    };

    // FIX: Clone window for drag callback
    let window_drag = window.clone();

    rsx! {
        div {
            style: "width: 100vw; height: 100vh; background: transparent;",
            div {
                style: "position: absolute; left: {region.read().x}px; top: {region.read().y}px; width: {region.read().width}px; height: {region.read().height}px; border: 2px dashed #00ff00; background: rgba(0, 255, 0, 0.1);",

                // Drag Handle
                div {
                    // FIX: Use cloned handle
                    onmousedown: move |_| window_drag.drag(),
                    style: "width: 100%; height: 30px; background: rgba(0,0,0,0.5); cursor: move; color: white;",
                    "Select Region"
                }

                // Confirm Button
                button {
                    onclick: confirm,
                    style: "position: absolute; bottom: -40px; left: 0; background: #00ff00; padding: 5px 10px;",
                    "Confirm"
                }
            }
        }
    }
}


================================================================================
FILE: core/region-selector/src/main.rs
================================================================================
//! Region Selector - Dioxus Implementation

#![allow(non_snake_case)]

mod app;

use app::App;
use dioxus::desktop::{Config, WindowBuilder};
use dioxus::prelude::*;

fn main() {
    // Transparent fullscreen window for overlay
    let cfg = Config::new()
        .with_window(
            WindowBuilder::new()
                .with_title("MandyGIF Region Selector")
                .with_transparent(true)
                .with_decorations(false)
                .with_always_on_top(true)
                .with_maximized(true),
        )
        .with_background_color((0, 0, 0, 0));

    LaunchBuilder::desktop().with_cfg(cfg).launch(App);
}


================================================================================
FILE: test_encoder.sh
================================================================================
#!/bin/bash
set -e

echo "Testing encoder with recording from recorder..."

# Make sure we have a test recording
if [ ! -f /tmp/test_recorder.mp4 ]; then
  echo "No test recording found. Run ./test_recorder.sh first"
  exit 1
fi

# Test 1: GIF encoding
echo "Test 1: Encoding GIF..."
echo '{"cmd":"gif","in":"/tmp/test_recorder.mp4","trim":{"start_ms":0,"end_ms":2700},"fps":15,"scale_px":480,"loop":"normal","captions":[],"out":"/tmp/test.gif"}' | cargo run --bin encoder --quiet 2>&1

if [ -f /tmp/test.gif ]; then
  SIZE=$(stat -c%s /tmp/test.gif 2>/dev/null || stat -f%z /tmp/test.gif)
  echo "âœ“ GIF created: /tmp/test.gif (${SIZE} bytes)"
else
  echo "âœ— GIF encoding failed"
  exit 1
fi

# Test 2: WebP encoding
echo "Test 2: Encoding WebP..."
echo '{"cmd":"webp","in":"/tmp/test_recorder.mp4","trim":{"start_ms":0,"end_ms":2700},"fps":15,"scale_px":480,"quality":0.85,"lossless":false,"captions":[],"out":"/tmp/test.webp"}' | cargo run --bin encoder --quiet 2>&1

if [ -f /tmp/test.webp ]; then
  SIZE=$(stat -c%s /tmp/test.webp 2>/dev/null || stat -f%z /tmp/test.webp)
  echo "âœ“ WebP created: /tmp/test.webp (${SIZE} bytes)"
else
  echo "âœ— WebP encoding failed"
  exit 1
fi

# Test 3: MP4 re-encoding
echo "Test 3: Re-encoding MP4..."
echo '{"cmd":"mp4","in":"/tmp/test_recorder.mp4","trim":{"start_ms":0,"end_ms":2700},"fps":30,"scale_px":640,"quality":0.8,"captions":[],"out":"/tmp/test_reencoded.mp4"}' | cargo run --bin encoder --quiet 2>&1

if [ -f /tmp/test_reencoded.mp4 ]; then
  SIZE=$(stat -c%s /tmp/test_reencoded.mp4 2>/dev/null || stat -f%z /tmp/test_reencoded.mp4)
  echo "âœ“ MP4 created: /tmp/test_reencoded.mp4 (${SIZE} bytes)"
else
  echo "âœ— MP4 encoding failed"
  exit 1
fi

echo ""
echo "âœ“ All encoder tests passed"
echo "Output files:"
echo "  - /tmp/test.gif"
echo "  - /tmp/test.webp" 
echo "  - /tmp/test_reencoded.mp4"

================================================================================
FILE: test_recorder.sh
================================================================================
#!/bin/bash
set -e

# Clean up any previous test files
rm -f /tmp/test_recorder.mp4

# Build first
echo "Building recorder..."
cargo build --bin recorder-linux --quiet

# Run recorder with automatic start/stop
echo "Starting 3-second test recording..."
(
  echo '{"cmd":"start","region":{"x":100,"y":100,"width":640,"height":480},"fps":30,"cursor":false,"out":"/tmp/test_recorder.mp4"}'
  sleep 3
  echo '{"cmd":"stop"}'
) | cargo run --bin recorder-linux --quiet 2>&1

# Verify the file exists and is valid
if [ -f /tmp/test_recorder.mp4 ]; then
  SIZE=$(stat -f%z /tmp/test_recorder.mp4 2>/dev/null || stat -c%s /tmp/test_recorder.mp4)
  echo "âœ“ Recording created: /tmp/test_recorder.mp4 (${SIZE} bytes)"
  
  # Check if ffprobe is available
  if command -v ffprobe &> /dev/null; then
    echo "âœ“ Validating with ffprobe..."
    ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 /tmp/test_recorder.mp4
  fi
  
  echo "âœ“ Test passed - you can play: mpv /tmp/test_recorder.mp4"
else
  echo "âœ— Test failed - no output file created"
  exit 1
fi

================================================================================
FILE: ui/Cargo.toml
================================================================================
[package]
name = "mandygif-ui"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[[bin]]
name = "mandygif"
path = "src/main.rs"

[dependencies]
mandygif-protocol = { path = "../core/protocol" }
mandygif-recorder-linux = { path = "../core/recorder-linux" }
anyhow.workspace = true
tokio.workspace = true
tracing.workspace = true
tracing-subscriber.workspace = true
serde.workspace = true
serde_json.workspace = true
dioxus = { version = "0.6", features = ["desktop"] }
dioxus-logger = "0.6"


================================================================================
FILE: ui/src/app.rs
================================================================================
#![allow(non_snake_case)]

use crate::components::control_bar::ControlBar;
use crate::components::resize_handle::ResizeHandles;
use crate::hooks::use_recorder;
use crate::state::{AppMode, AppState};
use dioxus::desktop::tao::dpi::LogicalSize;
use dioxus::desktop::use_window;
use dioxus::prelude::*;

#[allow(dependency_on_unit_never_type_fallback)]
pub fn App() -> Element {
    use_context_provider(AppState::new);
    let state = use_context::<AppState>();
    let window = use_window();
    let recorder = use_recorder();

    // Initial size
    let win_startup = window.clone();
    use_hook(move || {
        // FIX: Removed `let _ =` (clippy::let_unit_value)
        win_startup.set_inner_size(LogicalSize::new(800.0, 600.0));
    });

    let current_mode = *state.mode.read();
    let drag_win = window.clone();

    // Determine state class for CSS
    let state_class = match current_mode {
        AppMode::Recording => "state-recording",
        AppMode::Review | AppMode::Exporting => "state-review",
        // FIX: Explicit match (clippy::match_wildcard_for_single_variants)
        AppMode::Idle => "state-idle",
    };

    rsx! {
        style { dangerous_inner_html: include_str!("style.css") }

        div {
            class: "app-frame {state_class}",

            // 1. Resize Handles (Only when not recording)
            if current_mode == AppMode::Idle {
                ResizeHandles {}
            }

            // 2. Drag Header (Invisible but usable area at top)
            if current_mode == AppMode::Idle {
                div {
                    class: "drag-header",
                    onmousedown: move |_| drag_win.drag(),
                    // Optional: Visual indicator for drag area if needed
                }
            }

            // 3. Floating Control Bar
            ControlBar {
                on_record: recorder.start,
                on_stop: recorder.stop,
                on_export: recorder.export
            }
        }
    }
}


================================================================================
FILE: ui/src/components/control_bar.rs
================================================================================
// warden:ignore
use crate::components::icons::{IconExport, IconMic, IconRecord, IconSettings, IconStop};
use crate::state::{use_app_state, AppMode};
use dioxus::prelude::*;

#[component]
pub fn ControlBar(
    on_record: EventHandler<()>,
    on_stop: EventHandler<()>,
    on_export: EventHandler<()>,
) -> Element {
    let mut state = use_app_state();
    let mode = state.mode.read();
    let duration = state.duration_ms.read();

    // Calculate formatted time
    let d = *duration;
    let seconds = (d / 1000) % 60;
    let minutes = (d / 1000) / 60;
    let time_str = format!("{minutes:02}:{seconds:02}");

    rsx! {
        div {
            class: "control-pill",

            // Settings / Config (Left side)
            if *mode != AppMode::Recording {
                button { class: "icon-btn", title: "Microphone", IconMic {} }
                button { class: "icon-btn", title: "Settings", IconSettings {} }
                div { class: "pill-divider" }
            }

            // Main Action Button (Center)
            if *mode == AppMode::Recording {
                div { class: "timer", "{time_str}" }
                button {
                    class: "icon-btn btn-stop",
                    onclick: move |_| on_stop.call(()),
                    IconStop {}
                }
            } else if *mode == AppMode::Idle {
                button {
                    class: "icon-btn btn-record",
                    onclick: move |_| on_record.call(()),
                    IconRecord {}
                }
            } else if *mode == AppMode::Review {
                 // Export Section
                select {
                    class: "icon-btn",
                    style: "font-size: 12px; width: auto; padding: 4px 8px; border-radius: 4px;",
                    onchange: move |evt| state.export_format.set(evt.value()),
                    option { value: "gif", "GIF" }
                    option { value: "mp4", "MP4" }
                    option { value: "webp", "WebP" }
                }
                button {
                    class: "icon-btn",
                    style: "color: white; gap: 6px; padding-right: 12px; width: auto; border-radius: 20px; background: #007AFF;",
                    onclick: move |_| on_export.call(()),
                    IconExport {}
                    span { "Export" }
                }
                button {
                    class: "icon-btn",
                    title: "Discard",
                    onclick: move |_| state.mode.set(AppMode::Idle),
                    "âœ•"
                }
            } else if *mode == AppMode::Exporting {
                div {
                    style: "color: var(--text-secondary); font-size: 13px;",
                    "Rendering..."
                }
            }
        }
    }
}


================================================================================
FILE: ui/src/components/icons.rs
================================================================================
// warden:ignore
use dioxus::prelude::*;

pub fn IconMic() -> Element {
    rsx! {
        svg {
            width: "20", height: "20", view_box: "0 0 24 24", fill: "none", stroke: "currentColor", stroke_width: "2", stroke_linecap: "round", stroke_linejoin: "round",
            path { d: "M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z" }
            path { d: "M19 10v2a7 7 0 0 1-14 0v-2" }
            line { x1: "12", y1: "19", x2: "12", y2: "23" }
            line { x1: "8", y1: "23", x2: "16", y2: "23" }
        }
    }
}

pub fn IconSettings() -> Element {
    rsx! {
        svg {
            width: "20", height: "20", view_box: "0 0 24 24", fill: "none", stroke: "currentColor", stroke_width: "2", stroke_linecap: "round", stroke_linejoin: "round",
            circle { cx: "12", cy: "12", r: "3" }
            path { d: "M19.4 15a1.65 1.65 0 0 0 .33 1.82l.06.06a2 2 0 0 1 0 2.83 2 2 0 0 1-2.83 0l-.06-.06a1.65 1.65 0 0 0-1.82-.33 1.65 1.65 0 0 0-1 1.51V21a2 2 0 0 1-2 2 2 2 0 0 1-2-2v-.09A1.65 1.65 0 0 0 9 19.4a1.65 1.65 0 0 0-1.82.33l-.06.06a2 2 0 0 1-2.83 0 2 2 0 0 1 0-2.83l.06-.06a1.65 1.65 0 0 0 .33-1.82 1.65 1.65 0 0 0-1.51-1H3a2 2 0 0 1-2-2 2 2 0 0 1 2-2h.09A1.65 1.65 0 0 0 5 9a1.65 1.65 0 0 0-.33-1.82l-.06-.06a2 2 0 0 1 0-2.83 2 2 0 0 1 2.83 0l.06.06a1.65 1.65 0 0 0 1.82.33H9a1.65 1.65 0 0 0 1-1.51V3a2 2 0 0 1 2-2 2 2 0 0 1 2 2v.09a1.65 1.65 0 0 0 1 1.51 1.65 1.65 0 0 0 1.82-.33l.06-.06a2 2 0 0 1 2.83 0 2 2 0 0 1 0 2.83l-.06.06a1.65 1.65 0 0 0-.33 1.82V9a1.65 1.65 0 0 0 1.51 1H21a2 2 0 0 1 2 2 2 2 0 0 1-2 2h-.09a1.65 1.65 0 0 0-1.51 1z" }
        }
    }
}

pub fn IconRecord() -> Element {
    rsx! {
        div {
            style: "width: 14px; height: 14px; background: currentColor; border-radius: 50%;"
        }
    }
}

pub fn IconStop() -> Element {
    rsx! {
        div {
            style: "width: 14px; height: 14px; background: currentColor; border-radius: 2px;"
        }
    }
}

pub fn IconExport() -> Element {
    rsx! {
        svg {
            width: "18", height: "18", view_box: "0 0 24 24", fill: "none", stroke: "currentColor", stroke_width: "2", stroke_linecap: "round", stroke_linejoin: "round",
            path { d: "M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4" }
            polyline { points: "17 8 12 3 7 8" }
            line { x1: "12", y1: "3", x2: "12", y2: "15" }
        }
    }
}


================================================================================
FILE: ui/src/components/resize_handle.rs
================================================================================
// warden:ignore
use dioxus::desktop::tao::window::ResizeDirection;
use dioxus::desktop::use_window;
use dioxus::prelude::*;

#[component]
pub fn ResizeHandles() -> Element {
    let window = use_window();

    // Helper to generate a handle div
    let make_handle = move |dir: ResizeDirection, class: &'static str| {
        let w = window.clone();
        rsx! {
            div {
                class: "resize-zone {class}",
                style: match dir {
                    ResizeDirection::North => "top: 0; left: 10px; right: 10px; height: 6px; cursor: n-resize;",
                    ResizeDirection::South => "bottom: 0; left: 10px; right: 10px; height: 6px; cursor: s-resize;",
                    ResizeDirection::East => "top: 10px; bottom: 10px; right: 0; width: 6px; cursor: e-resize;",
                    ResizeDirection::West => "top: 10px; bottom: 10px; left: 0; width: 6px; cursor: w-resize;",
                    ResizeDirection::NorthWest => "top: 0; left: 0; width: 10px; height: 10px; cursor: nw-resize;",
                    ResizeDirection::NorthEast => "top: 0; right: 0; width: 10px; height: 10px; cursor: ne-resize;",
                    ResizeDirection::SouthWest => "bottom: 0; left: 0; width: 10px; height: 10px; cursor: sw-resize;",
                    ResizeDirection::SouthEast => "bottom: 0; right: 0; width: 10px; height: 10px; cursor: se-resize;",
                },
                onmousedown: move |_| { let _ = w.drag_resize_window(dir); },
            }
        }
    };

    rsx! {
        // Corners
        {make_handle(ResizeDirection::NorthWest, "")}
        {make_handle(ResizeDirection::NorthEast, "")}
        {make_handle(ResizeDirection::SouthWest, "")}
        {make_handle(ResizeDirection::SouthEast, "")}

        // Sides
        {make_handle(ResizeDirection::North, "")}
        {make_handle(ResizeDirection::South, "")}
        {make_handle(ResizeDirection::West, "")}
        {make_handle(ResizeDirection::East, "")}
    }
}


================================================================================
FILE: ui/src/hooks.rs
================================================================================
#![allow(clippy::cast_possible_truncation)]
#![allow(clippy::cast_sign_loss)]

use crate::processes::{run_encoder, run_recorder};
use crate::state::{use_app_state, AppMode};
use dioxus::desktop::tao::dpi::PhysicalPosition;
use dioxus::desktop::use_window;
use dioxus::prelude::*;
use mandygif_protocol::RecorderEvent;
use tokio::sync::mpsc;

pub struct RecorderController {
    pub start: Callback<()>,
    pub stop: Callback<()>,
    pub export: Callback<()>,
}

pub fn use_recorder() -> RecorderController {
    let mut state = use_app_state();
    let window = use_window();
    let rec_window = window.clone();

    // FIX: Wrap closure in Callback::new()
    let start = Callback::new(move |()| {
        if *state.mode.read() == AppMode::Recording {
            return;
        }

        let outer_pos = rec_window
            .outer_position()
            .unwrap_or(PhysicalPosition::new(0, 0));
        let outer_size = rec_window.outer_size();

        let region = mandygif_protocol::CaptureRegion {
            x: outer_pos.x + 1,
            y: outer_pos.y + 1,
            width: outer_size.width - 2,
            height: outer_size.height - 2,
        };

        state.mode.set(AppMode::Recording);
        state.duration_ms.set(0);

        let (tx, mut rx) = mpsc::unbounded_channel();
        let (stop_tx, mut stop_rx) = mpsc::unbounded_channel();
        state.stop_tx.set(Some(stop_tx));

        spawn(async move {
            if let Err(e) = run_recorder(tx, &mut stop_rx, region).await {
                tracing::error!("Recorder failed: {e}");
            }
        });

        spawn(async move {
            while let Some(event) = rx.recv().await {
                match event {
                    RecorderEvent::Progress { pts_ms } => {
                        state.duration_ms.set(pts_ms as i32);
                    }
                    RecorderEvent::Stopped { duration_ms, path } => {
                        state.mode.set(AppMode::Review);
                        state.duration_ms.set(duration_ms as i32);
                        state.rec_path.set(Some(path));
                        state.stop_tx.set(None);
                    }
                    RecorderEvent::Error { hint, .. } => {
                        tracing::error!("Recorder Error: {hint}");
                        state.mode.set(AppMode::Idle);
                        state.stop_tx.set(None);
                    }
                    RecorderEvent::Started { .. } => {}
                }
            }
        });
    });

    // FIX: Wrap closure in Callback::new()
    let stop = Callback::new(move |()| {
        if let Some(tx) = state.stop_tx.take() {
            let _ = tx.send(());
        }
    });

    // FIX: Wrap closure in Callback::new()
    let export = Callback::new(move |()| {
        let Some(path) = state.rec_path.read().clone() else {
            return;
        };
        let fmt = state.export_format.read().clone();
        let fps = *state.export_fps.read();
        let scale = *state.export_scale.read();
        let dur = *state.duration_ms.read() as u64;

        state.mode.set(AppMode::Exporting);

        spawn(async move {
            if let Err(e) = run_encoder(path, &fmt, fps, (0, dur), scale).await {
                tracing::error!("Encoder failed: {e}");
            }
            state.mode.set(AppMode::Idle);
        });
    });

    RecorderController {
        start,
        stop,
        export,
    }
}


================================================================================
FILE: ui/src/main.rs
================================================================================
//! `MandyGIF` - Dioxus UI

#![allow(non_snake_case)]

mod app;
mod hooks;
mod components {
    pub mod control_bar;
    pub mod icons;
    pub mod resize_handle;
}
mod processes;
mod state;

use app::App;
use dioxus::desktop::{Config, WindowBuilder};
// FIX: Switch back to LogicalSize for High DPI support
use dioxus::desktop::tao::dpi::LogicalSize;
use dioxus::prelude::*;

fn main() {
    dioxus_logger::init(tracing::Level::INFO).expect("failed to init logger");

    let cfg = Config::new()
        .with_window(
            WindowBuilder::new()
                .with_title("MandyGIF")
                .with_transparent(true)
                .with_decorations(false)
                .with_always_on_top(true)
                .with_maximized(false)
                .with_resizable(true)
                // FIX: Use LogicalSize 800x600
                .with_inner_size(LogicalSize::new(800.0, 600.0)),
        )
        .with_background_color((0, 0, 0, 0));

    LaunchBuilder::desktop().with_cfg(cfg).launch(App);
}


================================================================================
FILE: ui/src/processes.rs
================================================================================
#![allow(clippy::wildcard_imports)]
#![allow(clippy::match_same_arms)]
#![allow(clippy::uninlined_format_args)]

use anyhow::{Context, Result};
use mandygif_protocol::*;
use mandygif_recorder_linux::Recorder;
use std::path::PathBuf;
use std::time::Duration;
use tokio::io::{AsyncBufReadExt, AsyncWriteExt, BufReader};
use tokio::process::Command;
use tokio::sync::mpsc;
use tracing::{error, info};

/// Run recorder directly in this process.
pub async fn run_recorder(
    tx: mpsc::UnboundedSender<RecorderEvent>,
    stop_rx: &mut mpsc::UnboundedReceiver<()>,
    region: CaptureRegion,
) -> Result<()> {
    Recorder::init()?;

    let out_path = PathBuf::from("/tmp/mandygif_recording.mp4");

    // Pass references to match library signature
    let recorder = Recorder::start(&region, 30, false, &out_path)?;

    let _ = tx.send(RecorderEvent::Started { pts_ms: 0 });

    loop {
        tokio::select! {
            _ = stop_rx.recv() => {
                info!("Stop signal received");
                break;
            }
            // FIX: Explicitly match the unit result from sleep
            () = tokio::time::sleep(Duration::from_millis(100)) => {
                let ms = recorder.duration_ms();
                let _ = tx.send(RecorderEvent::Progress { pts_ms: ms });
            }
        }
    }

    let duration = recorder.stop()?;

    let _ = tx.send(RecorderEvent::Stopped {
        duration_ms: duration,
        path: out_path,
    });

    Ok(())
}

pub async fn run_encoder(
    input: PathBuf,
    fmt: &str,
    fps: u32,
    trim: (u64, u64),
    scale: u32,
) -> Result<()> {
    let exe = std::env::current_exe()?;
    let bin_dir = exe
        .parent()
        .context("Failed to determine executable directory")?;
    let bin = bin_dir.join("encoder");

    let mut child = Command::new(&bin)
        .stdin(std::process::Stdio::piped())
        .stdout(std::process::Stdio::piped())
        .spawn()
        .context("Failed to spawn encoder process")?;

    let cmd = build_encode_cmd(input, fmt, fps, trim, scale);

    if let Some(mut stdin) = child.stdin.take() {
        let json = to_jsonl(&cmd)?;
        stdin.write_all(json.as_bytes()).await?;
    }

    let stdout = child
        .stdout
        .take()
        .context("Failed to open encoder stdout")?;
    let mut reader = BufReader::new(stdout).lines();

    while let Ok(Some(line)) = reader.next_line().await {
        if let Ok(event) = parse_encoder_event(&line) {
            match event {
                EncoderEvent::Done { path } => info!("Export done: {:?}", path),
                EncoderEvent::Error { hint, .. } => error!("Export error: {}", hint),
                EncoderEvent::Progress { .. } => {}
            }
        }
    }

    child.wait().await?;
    Ok(())
}

fn build_encode_cmd(
    input: PathBuf,
    fmt: &str,
    fps: u32,
    trim: (u64, u64),
    scale: u32,
) -> EncoderCommand {
    let tr = TrimRange {
        start_ms: trim.0,
        end_ms: trim.1,
    };
    let out = PathBuf::from(format!("/tmp/export.{}", fmt));

    match fmt {
        "gif" => EncoderCommand::Gif {
            input,
            trim: tr,
            fps,
            scale_px: Some(scale),
            loop_mode: LoopMode::Normal,
            captions: vec![],
            out,
        },
        "webp" => EncoderCommand::Webp {
            input,
            trim: tr,
            fps,
            scale_px: Some(scale),
            quality: 0.8,
            lossless: false,
            captions: vec![],
            out,
        },
        _ => EncoderCommand::Mp4 {
            input,
            trim: tr,
            fps,
            scale_px: Some(scale),
            quality: 0.8,
            captions: vec![],
            out,
        },
    }
}


================================================================================
FILE: ui/src/state.rs
================================================================================
use dioxus::prelude::*;
use std::path::PathBuf;
use tokio::sync::mpsc::UnboundedSender;

#[derive(Clone, Copy, Debug, PartialEq)]
pub enum AppMode {
    Idle,
    Recording,
    Review,
    Exporting,
}

#[derive(Clone, Copy, Debug)]
pub struct AppState {
    pub mode: Signal<AppMode>,
    pub duration_ms: Signal<i32>,
    pub rec_path: Signal<Option<PathBuf>>,
    pub stop_tx: Signal<Option<UnboundedSender<()>>>,
    pub export_format: Signal<String>,
    pub export_fps: Signal<u32>,
    pub export_scale: Signal<u32>,
}

impl AppState {
    pub fn new() -> Self {
        Self {
            mode: Signal::new(AppMode::Idle),
            duration_ms: Signal::new(0),
            rec_path: Signal::new(None),
            stop_tx: Signal::new(None),
            export_format: Signal::new("gif".to_string()),
            export_fps: Signal::new(15),
            export_scale: Signal::new(480),
        }
    }
}

pub fn use_app_state() -> AppState {
    use_context::<AppState>()
}


================================================================================
FILE: ui/src/style.css
================================================================================
:root {
    --bg-glass: rgba(20, 20, 20, 0.6);
    --bg-pill: rgba(28, 28, 32, 0.95);
    --border-glass: rgba(255, 255, 255, 0.1);
    --accent-red: #ff3b30;
    --accent-green: #34c759;
    --text-primary: #ffffff;
    --text-secondary: #8e8e93;
    --radius-lg: 16px;
    --radius-pill: 9999px;
}

html,
body {
    margin: 0;
    padding: 0;
    width: 100%;
    height: 100%;
    background: transparent;
    overflow: hidden;
    font-family:
        -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial,
        sans-serif;
    user-select: none;
}

/* Main Container */
.app-frame {
    position: fixed;
    inset: 0;
    border-radius: var(--radius-lg);
    transition: box-shadow 0.3s ease;
    pointer-events: none; /* Let clicks pass through the empty center */
}

/* Recording Border State */
.state-idle {
    box-shadow: inset 0 0 0 2px rgba(255, 255, 255, 0.2);
}

.state-recording {
    box-shadow: inset 0 0 0 4px var(--accent-red);
}

.state-review {
    box-shadow: inset 0 0 0 2px var(--accent-green);
    background: rgba(0, 0, 0, 0.2);
    pointer-events: auto; /* Block clicks during review */
}

/* Header / Drag Area */
.drag-header {
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 40px;
    display: flex;
    align-items: center;
    justify-content: center;
    cursor: grab;
    pointer-events: auto;
    z-index: 100;
}

.drag-header:active {
    cursor: grabbing;
}

/* Floating Control Pill */
.control-pill {
    position: absolute;
    bottom: 24px;
    left: 50%;
    transform: translateX(-50%);

    display: flex;
    align-items: center;
    gap: 16px;
    padding: 8px 20px;

    background: var(--bg-pill);
    border: 1px solid var(--border-glass);
    border-radius: var(--radius-pill);
    backdrop-filter: blur(20px);
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.4);

    pointer-events: auto;
    z-index: 200;
    transition: transform 0.2s cubic-bezier(0.2, 0.8, 0.2, 1);
}

.control-pill:hover {
    transform: translateX(-50%) translateY(-2px);
    box-shadow: 0 12px 40px rgba(0, 0, 0, 0.5);
}

/* Buttons */
.icon-btn {
    background: transparent;
    border: none;
    color: var(--text-secondary);
    cursor: pointer;
    padding: 8px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s ease;
}

.icon-btn:hover {
    color: var(--text-primary);
    background: rgba(255, 255, 255, 0.1);
}

.btn-record {
    width: 48px;
    height: 48px;
    padding: 0;
    border-radius: 50%;
    background: rgba(255, 59, 48, 0.2);
    color: var(--accent-red);
    border: 1px solid rgba(255, 59, 48, 0.3);
}

.btn-record:hover {
    background: var(--accent-red);
    color: white;
    transform: scale(1.1);
}

.btn-stop {
    width: 48px;
    height: 48px;
    background: rgba(255, 255, 255, 0.1);
    color: white;
}

.btn-stop:hover {
    background: rgba(255, 255, 255, 0.2);
}

/* Typography */
.timer {
    font-variant-numeric: tabular-nums;
    color: var(--accent-red);
    font-weight: 600;
    font-size: 14px;
    min-width: 45px;
    text-align: center;
}

.pill-divider {
    width: 1px;
    height: 20px;
    background: rgba(255, 255, 255, 0.1);
}

/* Resize Handles - Invisible but interactable */
.resize-zone {
    position: absolute;
    z-index: 50;
    background: transparent;
}


